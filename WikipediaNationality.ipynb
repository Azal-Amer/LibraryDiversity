{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wikipedia\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import re\n",
    "api = \"https://www.googleapis.com/books/v1/volumes?q=title:\"\n",
    "isbnAPI = \"https://www.googleapis.com/books/v1/volumes?q=isbn:\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big idea- Using wikipedia pages to infer ethnicity\n",
    "Keywords and permulations\n",
    "- taking the associated catagories that are used, and using nltk's wordnet to find all associated words\n",
    "Searching\n",
    "- opening up the author's wikipedia article, and searching for the frequencies of all the keywords. At the end of the search, whichever catagory has the most mentions, is the catagory the author is sorted into\n",
    "- if there are no mentions, check the author's birthplace and parse that\n",
    "- if no birthplace, people assume whiteness inherently when writting, so the same must be done. That OR the prediction thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amer_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "asian = np.asarray(['china','japan','korea','taiwan','east-asian','japanese','korean','chinese','taiwanese','india','pakistan','bangledesh','nepal','south-asian','hindi','urdu'])\n",
    "black = np.asarray(['african-american','nigera','ethiopia','egypt','african','nigerian','ethiopian','egyptian'])\n",
    "# black != african, but african is a subset of black.\n",
    "white = np.asarray(['european','caucasian'])\n",
    "hispanic = np.asarray(['hispanic','mexico','spanish','Latino','Latin'])\n",
    "keywords = np.asarray([asian,black,white,hispanic])\n",
    "keywordTitles = ['asian','black','white','hispanic']\n",
    "for j in range(len(keywords)):\n",
    "    for i in range(len(keywords[j])):\n",
    "        for ss in wn.synsets(keywords[j][i]):\n",
    "            keywords[j] = np.append(keywords[j],np.asarray(ss.lemma_names()),axis = None)\n",
    "    keywords[j].flatten()\n",
    "    keywords[j] = list(np.unique(keywords[j]))\n",
    "\n",
    "keywordDF = (pd.DataFrame(keywords).T)\n",
    "\n",
    "keywordDF.columns =keywordTitles\n",
    "# keywordDF.set_index(['asian']).apply(pd.Series.explode).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBookInfo(title):\n",
    "    title = title.replace(' ', '%')\n",
    "    url = api + title\n",
    "    response = urlopen(url)\n",
    "    data = json.loads(response.read())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>Title</th>\n",
       "      <th>author</th>\n",
       "      <th>last</th>\n",
       "      <th>first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0747584680</td>\n",
       "      <td>Harry Potter and the Half-blood Prince</td>\n",
       "      <td>J. Rowling</td>\n",
       "      <td>Rowling</td>\n",
       "      <td>J.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCLC:1237342842</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Hog...</td>\n",
       "      <td>J. Rowling</td>\n",
       "      <td>Rowling</td>\n",
       "      <td>J.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9781781100509</td>\n",
       "      <td>Harry Potter and the Chamber of Secrets</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>Rowling</td>\n",
       "      <td>J.K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9781408855911</td>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban</td>\n",
       "      <td>J. Rowling</td>\n",
       "      <td>Rowling</td>\n",
       "      <td>J.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0439827604</td>\n",
       "      <td>The Harry Potter Collection</td>\n",
       "      <td>J. Rowling</td>\n",
       "      <td>Rowling</td>\n",
       "      <td>J.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>UOM:39015029412924</td>\n",
       "      <td>Anna Karénina ...</td>\n",
       "      <td>graf Tolstoy</td>\n",
       "      <td>Tolstoy</td>\n",
       "      <td>graf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>UOM:39015029412924</td>\n",
       "      <td>Anna Karénina ...</td>\n",
       "      <td>graf Tolstoy</td>\n",
       "      <td>Tolstoy</td>\n",
       "      <td>graf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>UOM:39015029412924</td>\n",
       "      <td>Anna Karénina ...</td>\n",
       "      <td>graf Tolstoy</td>\n",
       "      <td>Tolstoy</td>\n",
       "      <td>graf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1535179899</td>\n",
       "      <td>Untouchable</td>\n",
       "      <td>Sibel Hodge</td>\n",
       "      <td>Hodge</td>\n",
       "      <td>Sibel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>9780307560926</td>\n",
       "      <td>The Untouchable</td>\n",
       "      <td>John Banville</td>\n",
       "      <td>Banville</td>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  isbn                                              Title  \\\n",
       "0           0747584680             Harry Potter and the Half-blood Prince   \n",
       "1      OCLC:1237342842  Harry Potter and the Order of the Phoenix (Hog...   \n",
       "2        9781781100509            Harry Potter and the Chamber of Secrets   \n",
       "3        9781408855911           Harry Potter and the Prisoner of Azkaban   \n",
       "4           0439827604                        The Harry Potter Collection   \n",
       "..                 ...                                                ...   \n",
       "89  UOM:39015029412924                                  Anna Karénina ...   \n",
       "90  UOM:39015029412924                                  Anna Karénina ...   \n",
       "91  UOM:39015029412924                                  Anna Karénina ...   \n",
       "92          1535179899                                        Untouchable   \n",
       "93       9780307560926                                    The Untouchable   \n",
       "\n",
       "           author      last  first  \n",
       "0      J. Rowling   Rowling     J.  \n",
       "1      J. Rowling   Rowling     J.  \n",
       "2    J.K. Rowling   Rowling   J.K.  \n",
       "3      J. Rowling   Rowling     J.  \n",
       "4      J. Rowling   Rowling     J.  \n",
       "..            ...       ...    ...  \n",
       "89   graf Tolstoy   Tolstoy   graf  \n",
       "90   graf Tolstoy   Tolstoy   graf  \n",
       "91   graf Tolstoy   Tolstoy   graf  \n",
       "92    Sibel Hodge     Hodge  Sibel  \n",
       "93  John Banville  Banville   John  \n",
       "\n",
       "[94 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = ['How to Invent Everything','Percy Jackson','Oxford English Dictionary','The Fault in Our Stars','The Alchemist','The Hunger Games','To Kill a Mockingbird','The Kite Runner','0994047134','Fifteen Hundred Miles from the Sun']\n",
    "books = pd.read_csv('books.csv',on_bad_lines='skip')\n",
    "title = books['title'].to_list()[:100]\n",
    "namesDF = pd.DataFrame()\n",
    "for bookTitle in title:\n",
    "    try:\n",
    "        bookInfo = getBookInfo(bookTitle)['items'][0]['volumeInfo']\n",
    "        isbn13 = bookInfo['industryIdentifiers'][0]['identifier']\n",
    "        author = bookInfo['authors'][0].split(' ')\n",
    "        lastName = author[-1]\n",
    "        firstName = author[0]\n",
    "        name = firstName + ' ' + lastName\n",
    "        # Taking the first result for the search query which is index 0, getting information about the book and then printing the author of the book.\n",
    "        namesDF = namesDF.append({'isbn':isbn13,'Title':bookInfo['title'],'author' : name, 'last':lastName,'first': firstName},ignore_index=True)\n",
    "    except Exception as inst:\n",
    "        continue\n",
    "namesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sad\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "sad\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>Title</th>\n",
       "      <th>author</th>\n",
       "      <th>last</th>\n",
       "      <th>first</th>\n",
       "      <th>wikiPage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0747584680</td>\n",
       "      <td>Harry Potter and the Half-blood Prince</td>\n",
       "      <td>J. Rowling</td>\n",
       "      <td>Rowling</td>\n",
       "      <td>J.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCLC:1237342842</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Hog...</td>\n",
       "      <td>J. Rowling</td>\n",
       "      <td>Rowling</td>\n",
       "      <td>J.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9781781100509</td>\n",
       "      <td>Harry Potter and the Chamber of Secrets</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>Rowling</td>\n",
       "      <td>J.K.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9781408855911</td>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban</td>\n",
       "      <td>J. Rowling</td>\n",
       "      <td>Rowling</td>\n",
       "      <td>J.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0439827604</td>\n",
       "      <td>The Harry Potter Collection</td>\n",
       "      <td>J. Rowling</td>\n",
       "      <td>Rowling</td>\n",
       "      <td>J.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>UOM:39015029412924</td>\n",
       "      <td>Anna Karénina ...</td>\n",
       "      <td>graf Tolstoy</td>\n",
       "      <td>Tolstoy</td>\n",
       "      <td>graf</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Aleksey_Nikolaye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>UOM:39015029412924</td>\n",
       "      <td>Anna Karénina ...</td>\n",
       "      <td>graf Tolstoy</td>\n",
       "      <td>Tolstoy</td>\n",
       "      <td>graf</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Aleksey_Nikolaye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>UOM:39015029412924</td>\n",
       "      <td>Anna Karénina ...</td>\n",
       "      <td>graf Tolstoy</td>\n",
       "      <td>Tolstoy</td>\n",
       "      <td>graf</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Aleksey_Nikolaye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1535179899</td>\n",
       "      <td>Untouchable</td>\n",
       "      <td>Sibel Hodge</td>\n",
       "      <td>Hodge</td>\n",
       "      <td>Sibel</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List_of_British_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>9780307560926</td>\n",
       "      <td>The Untouchable</td>\n",
       "      <td>John Banville</td>\n",
       "      <td>Banville</td>\n",
       "      <td>John</td>\n",
       "      <td>https://en.wikipedia.org/wiki/John_Banville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  isbn                                              Title  \\\n",
       "0           0747584680             Harry Potter and the Half-blood Prince   \n",
       "1      OCLC:1237342842  Harry Potter and the Order of the Phoenix (Hog...   \n",
       "2        9781781100509            Harry Potter and the Chamber of Secrets   \n",
       "3        9781408855911           Harry Potter and the Prisoner of Azkaban   \n",
       "4           0439827604                        The Harry Potter Collection   \n",
       "..                 ...                                                ...   \n",
       "89  UOM:39015029412924                                  Anna Karénina ...   \n",
       "90  UOM:39015029412924                                  Anna Karénina ...   \n",
       "91  UOM:39015029412924                                  Anna Karénina ...   \n",
       "92          1535179899                                        Untouchable   \n",
       "93       9780307560926                                    The Untouchable   \n",
       "\n",
       "           author      last  first  \\\n",
       "0      J. Rowling   Rowling     J.   \n",
       "1      J. Rowling   Rowling     J.   \n",
       "2    J.K. Rowling   Rowling   J.K.   \n",
       "3      J. Rowling   Rowling     J.   \n",
       "4      J. Rowling   Rowling     J.   \n",
       "..            ...       ...    ...   \n",
       "89   graf Tolstoy   Tolstoy   graf   \n",
       "90   graf Tolstoy   Tolstoy   graf   \n",
       "91   graf Tolstoy   Tolstoy   graf   \n",
       "92    Sibel Hodge     Hodge  Sibel   \n",
       "93  John Banville  Banville   John   \n",
       "\n",
       "                                             wikiPage  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "..                                                ...  \n",
       "89  https://en.wikipedia.org/wiki/Aleksey_Nikolaye...  \n",
       "90  https://en.wikipedia.org/wiki/Aleksey_Nikolaye...  \n",
       "91  https://en.wikipedia.org/wiki/Aleksey_Nikolaye...  \n",
       "92  https://en.wikipedia.org/wiki/List_of_British_...  \n",
       "93        https://en.wikipedia.org/wiki/John_Banville  \n",
       "\n",
       "[94 rows x 6 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikiPages = []\n",
    "for i,author in enumerate(namesDF['author']):\n",
    "    \n",
    "    page_object =[]\n",
    "    bookTitle= namesDF['Title'][i]\n",
    "    bookTitle = bookTitle.split(',')[0]\n",
    "    titleSplitter = bookTitle.split(' ')\n",
    "    if titleSplitter[0] == 'The':\n",
    "        bookTitle = bookTitle[4:]\n",
    "    bookTitle = re.sub(r\"\\([^()]*\\)\", \"\", bookTitle)\n",
    "    # remove anything in parentheses\n",
    "    # The word 'the' may be lowercased on wikipedia, so if it is even there, its easier to just remove it.\n",
    "    try:\n",
    "        page_object = wikipedia.page(wikipedia.search(author)[0])\n",
    "    except Exception as inst:\n",
    "        try:\n",
    "            try:\n",
    "                temp_object = wikipedia.page(author + ' (author)')\n",
    "                arr =str(temp_object.title).split(' ')\n",
    "                nameCheck = (namesDF['first'][i] in arr) and (namesDF['last'][i] in arr)\n",
    "                if nameCheck==False:\n",
    "                    raise Exception('Name not found')\n",
    "                elif (temp_object.content.find(bookTitle) != -1):\n",
    "                    page_object = temp_object\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                # wikiPages.append('NaN')\n",
    "                continue\n",
    "            # This line?\n",
    "            # Checks if out of the list of pages,  if the author flag helps identify the author page\n",
    "        except Exception as e:\n",
    "            searches = wikipedia.search(author)[1:]            \n",
    "            for search in (searches):\n",
    "                # goes through every suggested search result, checks for the authors full name, and checks if the book title is mentioned somewhere\n",
    "\n",
    "                # if the first and last names aren't in any of the searches, it will throw an error.\n",
    "                arr = str(search).split(' ')\n",
    "                nameCheck = (namesDF['first'][i] in arr) and (namesDF['last'][i] in arr)\n",
    "                # check if both the first, and last name are i the search\n",
    "                if nameCheck:\n",
    "                    temp_object = wikipedia.page(search)\n",
    "                    \n",
    "                    if(temp_object.content.find(bookTitle) != -1):\n",
    "                        \n",
    "                        page_object = temp_object\n",
    "                        # checks if the page is about the author\n",
    "                        break\n",
    "    if(page_object==[]):\n",
    "        wikiPages.append('NaN')\n",
    "        continue\n",
    "    else:\n",
    "        wikiPages.append(page_object)\n",
    "\n",
    "    \n",
    "namesDF['wikiPage'] = wikiPages\n",
    "namesDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "Page id \"\"The Significance of Middleton's Title The Changeling\"\" does not match any pages. Try another id!\n",
      "list index out of range\n",
      "Page id \"\"Ruby Ann's Down Home Trailer Park Cookbook\"\" does not match any pages. Try another id!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>Title</th>\n",
       "      <th>author</th>\n",
       "      <th>last</th>\n",
       "      <th>first</th>\n",
       "      <th>wikiPage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>OCLC:27664149</td>\n",
       "      <td>The Significance of Middleton's Title The Chan...</td>\n",
       "      <td>Helen Bersie</td>\n",
       "      <td>Bersie</td>\n",
       "      <td>Helen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0071457135</td>\n",
       "      <td>The Ultimate Guide To Choosing a Medical Speci...</td>\n",
       "      <td>Brian Freeman</td>\n",
       "      <td>Freeman</td>\n",
       "      <td>Brian</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>9781449373696</td>\n",
       "      <td>Ruby Cookbook</td>\n",
       "      <td>Lucas Carlson</td>\n",
       "      <td>Carlson</td>\n",
       "      <td>Lucas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>9780806537924</td>\n",
       "      <td>Ruby Ann's Down Home Trailer Park Cookbook</td>\n",
       "      <td>Ruby Boxcar</td>\n",
       "      <td>Boxcar</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             isbn                                              Title  \\\n",
       "33  OCLC:27664149  The Significance of Middleton's Title The Chan...   \n",
       "59     0071457135  The Ultimate Guide To Choosing a Medical Speci...   \n",
       "79  9781449373696                                      Ruby Cookbook   \n",
       "80  9780806537924         Ruby Ann's Down Home Trailer Park Cookbook   \n",
       "\n",
       "           author     last  first wikiPage  \n",
       "33   Helen Bersie   Bersie  Helen      NaN  \n",
       "59  Brian Freeman  Freeman  Brian      NaN  \n",
       "79  Lucas Carlson  Carlson  Lucas      NaN  \n",
       "80    Ruby Boxcar   Boxcar   Ruby      NaN  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(namesDF['author']))\n",
    "for index,page in namesDF.loc[namesDF['wikiPage'] == 'NaN'].iterrows():\n",
    "    try:\n",
    "        webpage = wikipedia.page(page[1])\n",
    "        links = list(webpage.links)\n",
    "        # check if the last name is anywhere in the page links\n",
    "        for i in range(len(links)):\n",
    "\n",
    "            lastname = page[3]\n",
    "\n",
    "            if(lastname in str(links[i]).split(' ')):\n",
    "                namesDF.at[index,'wikiPage'] = (wikipedia.page(\"\\\"\"+links[i]+'\\\"'))\n",
    "            # if any(page[4] in word for word in links):\n",
    "            #     print('found')\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            webpage = wikipedia.page(\"\\\"\"+page[1]+'\\\"')\n",
    "            links = list(webpage.links)\n",
    "            pingedLinks = []\n",
    "            # check if the last name is anywhere in the page links\n",
    "            for i in range(len(links)):\n",
    "\n",
    "                lastname = page[3]\n",
    "                \n",
    "                if(lastname in str(links[i]).split(' ')):\n",
    "                    pingedLinks.append(links[i])\n",
    "\n",
    "\n",
    "            j = len(pingedLinks[0])\n",
    "            winner = pingedLinks[0]\n",
    "            if len(pingedLinks)>1:\n",
    "                # if there are multiple links with the Author's last name, pick the one with the least characters.\n",
    "                # I decided on this cause sometimes if an author is super prolific, a possestion they have may have an article aswell \n",
    "                    for k in pingedLinks:\n",
    "                        if len(k)<j:\n",
    "                            j = len(k)\n",
    "                            winner = k\n",
    "                    if(lastname in str(wikipedia.page(\"\\\"\"+winner+'\\\"').title).split(' ')):\n",
    "                        print(namesDF.at[index,'wikiPage'])\n",
    "                        namesDF.at[index,'wikiPage'] = (wikipedia.page(\"\\\"\"+winner+'\\\"'))\n",
    "                        \n",
    "                        \n",
    "                    # find the one with teh least words\n",
    "\n",
    "            elif(lastname in str(wikipedia.page(\"\\\"\"+winner+'\\\"').title).split(' ')):\n",
    "                print(namesDF.at[index,'wikiPage'])\n",
    "                namesDF.at[index,'wikiPage'] = (wikipedia.page(\"\\\"\"+links[i]+'\\\"'))\n",
    "                \n",
    "            else: \n",
    "                raise Exception('Name not found')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "namesDF.loc[namesDF['wikiPage'] == 'NaN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'set_facecolor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-212-49733b823bae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpie\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamesDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnamesDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'wikiPage'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'NaN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamesDF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Not Found'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Found'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautopct\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%1.1f%%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_facecolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'xkcd:mint green'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'set_facecolor'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR0AAADnCAYAAAAjFIKwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXjElEQVR4nO3debhVVcHH8e+6A5PgBhlFTRxQnBAVFZXBBkeccsiesl4HtNGh1MyyWlkOFZWVpmXpS1omIiiK8lbOhoIIiAg4oIgos7ABudxhn/X+sQ96gQv3Xjhnr7P3+X2e5zx3Omef3+WBH2tPaxnnHCIiSanwHUBEyotKR0QSpdIRkUSpdEQkUSodEUmUSkdEEqXSEZFEqXREJFEqHRFJlEpHRBKl0hGRRKl0RCRRKh0RSZRKR0QSpdIRkUSpdEQkUSodEUmUSkdEEqXSEZFEqXREJFEqHRFJlEpHRBKl0hGRRKl0RCRRKh0RSZRKR0QSpdIRkURV+Q4gRWaDAOgN7Nzo486Nvu4MmK086oFlwJL8Y3Gjz5cAH2DDRYn9PpJ6xjnnO4MUgg2qgYOAQ/Mf++c/dk3g3VcBr+UfrwLTgOnYsCaB95aUUemklQ06Ap8DjgWOBAYA7Twm2lQEzAYmA/8G/oUNV3lNJCVBpZMmNtgTOCX/GAa08RuoVSLgBeDx/GMGNtRfvjKk0illNqgAhgCnAsOBfn4DFdRiYCIwHngUG9Z7ziMJUemUIhvsAlyUf3zKc5okLAXuAf6CDef6DiPFpdIpFfGo5iTgEuJRTaXfQN78F/gLMBobrvMdRgpPpeObDXoDIyifUU1LrQbuA27R6CdbVDq+2GBn4IfAxaTrgHDScsA/geux4eu+w8j2U+kkzQbdge8D3wDae06TJhHxyOd6bPim7zCy7VQ6SbFBF+Bq4FKgo+c0aRYBfwd+hg3f8h1GWk+lU2w2aA9cBVwJBJ7TZEkDcBfwA2y4wncYaTmVTjHZ4CTgNmAP31EybAXx7upfdbFhOqh0iiE+I/V74CzfUcrIi8DF2HCW7yCydSqdQrPBhcBv0K6UD/XAjcCN2LDOdxhpmkqnUGywG3AncILvKMIs4Hxs+LLvILI5TeJVCDY4jXhKBxVOaTgQ+C82+LrvILI5jXS2R3zrws+Aa4knvJLScy/wNd1SUTpUOtvKBl2JL1Y7zncUadYs4Cxs+IbvIKLdq21jg4HAy6hw0uJAYCo2OMd3ENFIp/VsMAK4FWjrO4psk1uAK7FhzneQcqXSaQ0bjCS+sljS7QHgPJ1W90Ol0xLxAeM7iO8Il2z4P+BMHWBOnkqnOTaoIp7V7ou+o0jBTQJOwYYrfQcpJyqdrbFBO2A08RzFkk2vAsdjw8W+g5QLlc6WxEu8PAx8xncUKbp5wHHY8B3fQcqBSqcp8aqYE4FBvqNIYt4HjsaGC3wHyTpdp7MpG7QBxqLCKTe7ABPzk61JEal0NvdXtEtVrvYDxueP5UmRqHQas8HPgfN8xxCvBgN/z18mIUWgP9gNbHAx8eoMImcST8ImRaADybBhWtHxQJXvKFJSrsWGN/sOkTUqHRscAjyLVmiQzTngi9hwtO8gWVLepROfqZgO7O47ipSsNcBATYtROOV+TOduVDiydZ2AMfmlhKQAyrd0bHA5cLrvGJIKBxFPZyIFUJ67VzYYAExGa4hL63wBGz7gO0TalV/pxBd+TQUO8B1FUmcl0B8bLvQdJM3KcffqJlQ4sm26AH/ThYPbp7z+8GxwLHC57xiSap8GRvgOkWbls3sVT8b1CrC/7yiSeiuAfbHhCt9B0qicRjrfRoUjhdEVuMF3iLQqj5GODboDb6L1xaVwcsARWrq49cplpHMTKhwprArgNmyglV1bKfulEy+Md4HvGJJJRwIX+Q6RNtnevYr/F5qEZgGU4lkO7KMVJVou6yOdL6PCkeLqBlztO0SaZHekE1/A9RrQz3cUybwQ2B0bhr6DpEGWRzqno8KRZATEl2RIC2S5dK7xHUDKyuXYoIPvEGmQzdKJb3c40ncMKSvd0Vr3LZLN0oHv+w4gZekqbFDtO0Spy17pxHPlnOA7hpSlXYGv+g5R6rJXOjqWI35d5TtAqcvWKfP4HqsP0FIy4tcgbDjZd4hSlbWRzrmocMS/r/gOUMqyVjpaElhKwRd1QHnLslM6NtgbnSaX0tAVONl3iFKVndKBL/kOINKIzmJtQZZK58u+A4g0ckp+BVnZRDZKxwaHA/v4jiHSSBviExuyiWyUjnatpDSd7TtAKcpK6ZziO4BIEwbrJtDNpb90bNAH2Nt3DJEmtCVeJ0saSX/pwHG+A4hshe4D3EQWrt5V6UhJqXeV777m+ix4ODq6akI06LApvgOVmPTfe2WDJUAP3zGkfEXOLHvb7fzGhNyg3NhoyB4LXM9dG/3YAd3n3zxcq4HmpXukY4N9UOFIwpxj9Qd0nfuf6LCaMdHQ3q+6PfsST+LVFAMMAR5KLGCJS3fpwGDfAST7nKP2QzrNfjbXPxwTDev2Ym6/fhGVR7RiEyqdRtJeOsf4DiDZ4xy5j2g3d0qu39IHo6E7PpE7ZL/1tD1kOzY5pGDhMiDdx3Rs8BIw0HcMSb9aV/X2TLfnwnHR4DYTokH9Qjp2LuDmG4BO828evr6A20yttI909vUdQNIpchWL3nS7zHskOsqMiwbv+QHd9gT2LNLbVQF9gVebe6IxxgG/cc5dmf/6KqCjc85u5TVnAG8452Y38TNLPGH8svy3JjrnijaHuDFmPjDQObd8S89Jb+nYoDfQyXcMSYecY9VC12PuxNzAugejobu97j61B7BzghH2pQWlA9QCZxpjbtraP9xNnAE8CmxWOnm/dc6NbOG2ii69paOF9GQrnKNmOcHsp6IBax+IhvWY6vbZ11Hhc4nplt6Q3AD8GfgO8MPGPzDG9AHuIl7KeBlwAfFk8KcBw4wx1wFnOefmbe0NjDEG+CVwEvEp/Z875+43xhwLXOWcOyX/vFuBqc65/82PYEYBpwLVwDnOubnGmK7AfcAuwAvEZ+u2SqUjmeAcDWvoMOeF3P4rxkRDOz+TO3i/OqoP852rkdYcCrgNmGmM+eUm3/8DMMo5N8oYcyHwe+fcGcaY8cCjzrkxW9jed4wxG2bVvAboCAwADiYusJeMMc+2INdy59yhxphvEk9APwL4CfC8c+56Y8xw4KLmNqLSkdRa76rfnJ7ru+jB3JB2E6PD+62lw0G+M21Fi0vHObfaGPM34DKgptGPjgLOzH9+D/FopSU22r0yxvwWuM85FwFLjDHPAIcDq5vZztj8x5cb5Ri64XPn3ARjzMrmwqh0JDXqXeXCuW63d8ZHx1Q+VH9k31dGXd+3qlPUt8fZwzZ63vr3ZrHyiTupW/oO3U77Hjv0iy/nql+xkOWP/AqXi+h6wrdou8t+uFzE0tE/pvtZP6Kiul0x4/dp5fNvAaYBdxc8yZY1sPH9mJv+gdTmP0ZsR3ek+YZPTdqVcTlnVryd6/XCrQ2nP/fp2pEL+tbes+updTcOuTMafvS8qc91r+66W5Ovq9qxO11PvoId9t+4jNbMeJwun7uEHmdbVk8ZF39v+mPscMCni104AD36fH9Ciydrd859CIxm492VScAX859/GXgu//kaWndS5TngXGNMpTGmO/FoZQrwLrC/MaatMaYz8NkWbOtZ8vNZGWNOApqdLTHNI52evgNIYTnH2iV0mfOf6NB1Y6JhvWa4vfYBc9Smz2tYvZyat19ix6POZc1LD222naog/1fDbPx/qqmswtXX4hpqoaKS3Pq11Lw1hR5f+GlRfp9NGKA38T/slvo18O1GX18K3G2MuZpPDiQD/BO40xhzGXB2cweSgXHEu2qvEB9I/p5zbjGAMWY0MAt4B5jegow/Be4zxrxGXIoLmntBOi8OtEFbQBdapZxz1K2i45zncweufCAattOk3AH7NVDV7Ghg2bgb2fGoL+Dq1rF6yjh6nP2TJp+3fMJvab/X4R/vXjWsXsryR3+Di+rpesK3WTvrCTrsfQTtPtW/sL/Ylh0z/+bhk5J6s1KV1pFO4DuAtJ5zuBravj41t8+SB6OhO/w7d9h+62h3cGu2se6tKVTs0Jm2vfZm/YKZrXr/qh170OtLNwNQv/IDojUrqO66G8sf/TUuaqDzkPOo3mmXVm2zlXZt/inZl9bS6ew7gLRMnat8d5bb492HomOqH4mO2nclO/ZjO04C1L4/m5o3J7Nw3lRcVIerrWH5IyPpdmrrlhBf9ew9dB5yHqtffoSO/Y+nKujJymdH0f3Uq7c1Wkv0KubG0yKtpaORTomKnFk6z/V+c0I0yI3NDdnjPddjd2D3Qm2/y7Dz6TLsfADWL5jJ6injWl046xe8SmXHnajeaRdcfS0YA8bEnxdX+2K/QRqktXQ6+w4gMecI36fb3H9FA9ePiYbuOtv12QsPcxyteu5e2vTqS4e+R1K76A2Wjb2BXG18oDh8/h/0HvHHfF5HOOl+up1+DQCdDj6R5Y+OxOUidjr+m8WOqaWGSe+B5LOBB3zHKEfOsf5DOs15JndwOCYa2v3F3P79clRU+s6VEtfPv3l400e9y0haRzravUqIc0RraT93cq7fsjHR0B2fyh2yfy1ttmdumXLWxneAUpDW0knzRY0lr9ZVz3slnlum/YToyH1X0/EA35kyQrtXpLd0app/imwL56ivpqHLQPNGl4FVb3BD1V0R8KHvXFlQS3X9J9PalK+0lo4uDCwSY6g2uJ1858ii9tTp2Bfp3U3RSEfSqMF3gFKQ1pFOUUrndy/Wcue0ehxw8aHVXDGoLfbp9dw5rZ7uHeK5iW78bFtO7rv5rnlTrwW45t/refytBgb0quRvn48v07h3Zh3L17mPnyNlQ6WDSudjs5ZG3DmtnikX70CbSjjx3nWcsk9cLt8Z1Iarjt5yQWzptd07GKYtjpj5jY6MGF/Dq0si9t6pgrtn1DPxyx0K/StI6fvId4BSoN2rvDnLchy5SyUdqg1VFYZhu1cxdk79dr22wkB9FF+Qtq7eUV0JIyfVcekRbaiubHZWR8meJb4DlIK0lk7BDyQf2KOC5xZErFiXY12947G3GngvzAFw65Q6+t++lgsfrmFlzeYXU27ptZ3aGk7uW8Uhf/qInTtWELQ1TH4/4ox+OnNaphb5DlAK0npFck9gcaE3+9dpdfxxah07VBsO6F5B2yrDtYPb0K2DwRj40ZO1LFrruOv0zW+haeq1t5y48cRQI8bX8M3D2zBtUcS/5jXQv2cl1w3VcZ0yMgAbvuI7hG/NjnSMMZExZkajR59ihTHGnJ+fgb45S4G6Qr//RYe24eVLOvLsBTvQpb1hn64V9OxYQWWFocIYLj6sDVPej1r82samL4pwDvbtWsEDs+sZfU4H5q3M8eaKprcnmVTw/yjTqCW7VzXOuQGNHvOLHapZNnTAwkJvdulH8e7UgjDH2DkNfOmgahatyX3883Fz6jmwR9N/ZE29trEfPVXLzz7TlvocRPlNVgDrWnbYSNIvQlcGAtt49soYMwC4A+gAzAMudM6tNMY8TbxuzlRjTDfiNXP6GGPOJ16bpwOwFzDOOfe9/LYuAK4FVhFPn9jS+QXeo8ArMp41uoYV6+IDvred3I7O7QyXPr6eGYsjDNCncwV/OiXeZfpgTY4R49fzWP4sVFOv3eChufUM7F1B705xYQ3oVclBt6+lf88KDu6l68XKxDJsmGv+adnX7DEdY0zEJysTvuOc+7wxZiZwqXPuGWPM9cCOzrkrmimdHwOHEJfK68Bg4usWJgOHASHwFDDdOdd4Xtim2WAU8NXW/sIinszAhrpRlpaNdGqccwM2fGGMCYDOzrln8t8aRcummXjCORfmtzGbeGKnbsDTzrll+e/fT8tXeXizhc8TKQXNTlheLgp9yrzxujlbWjMHtnPdnDyVjqTJDN8BSkWrSyc/WllpjBmS/9ZXgA2jnvnEu0oAZ7dgc5OJ12DuaoypBs5pRRSVjqRJS5ZzKQvbOtr4H+AOY0wH4G0+WX9nJDDaGHMJMKG5jTjnFhljLPHC66to3f8GrxOPmHQkVtJghu8ApSKdFwduYIPpxAvBi5SyldhQ04XkpfU2iA3KfuEySYUZvgOUEpWOSPHpeE4jKh2R4lPpNJLu0rHhO+jOXSl9L/kOUErSXTqxF3wHENmKd7Dh675DlJIslI52saSUPeY7QKnJQuk86TuAyFaodDaR/tKx4XTgHd8xRJpQQ3wTszSS/tKJPeg7gEgTnsKGWi5pE1kpnTG+A4g0QbtWTchG6dhwMpo6QEqPSqcJ2Sid2FjfAUQaeSV/HZlsIkulo10sKSV3+w5QqrJUOpOAD3yHEAHqgb/7DlGqslM68QoRo3zHEAEewYbLfYcoVdkpndhtaJF68e8vvgOUsmyVjg3fR8d2xK+3gYm+Q5SybJVO7He+A0hZuyO/qy9bkL3SseGLxBO+iyRtPXCX7xClLnulE9NoR3y4Exuu8B2i1GW1dMYA7/sOIWWlBrjJd4g0yGbp2LAe+IPvGFJW7sCGmsWyBbJZOrFbgcW+Q0hZ+Ai42XeItMhu6djwI+DnvmNIWbgNGy71HSItsls6sT8D83yHkExbA/zSd4g0yXbpxMd2fuA7hmTa73XGqnWyXToANhwNPOc7hmTSYuBXvkOkTfZLJ3YFkPMdQjLnMmwY+g6RNuVROjachuY3kcJ6BBs+4DtEGpVH6cSuAhb6DiGZsAb4lu8QaVU+pWPDVcBFvmNIJlyHDd/zHSKtyqd0AGz4L+AO3zEk1aYQX3gq26i8Sid2Fbp2R7ZNA3AxNtRJie1QfqUTX6l8PjqbJa13HTac6TtE2pVf6QDY8Hng175jSKo8hA1/4TtEFpRn6cR+BEz3HUJS4S3i0bEUQPmWjg1rgdOBJb6jSElbB5yliwALp3xLB8if9jwDqPWcRErX13Ucp7DKu3Rgw5zKF/uOISXpDmx4j+8QWaPSAfJ/sXSQUBp7Abjcd4gsUul84gfAeN8hpCTMAU7BhnW+g2SRcU5L9HzMBh2B54GDfUcRbxYCR+s2h+LRSKcxG64FjgNm+Y4iXqwATlDhFJdKZ1M2XAZ8BhVPuVkFHI8NZ/sOknUqnaZ8Ujyv+o4iiVgDnJSfd0mKTKWzJSqecrEaGJ6/dEISoNLZGhsuJy4eXRyWTQuBwdhQc2gnSKXTnLh4Pgu87DuKFNQs4ChsqJFswlQ6LREXz1DgIc9JpDCeIh7haPpaD1Q6LWXD+MY/GOk7imyXfwAn6gZOf3Rx4LawwQXA7UBb31GkVX4BXIsN9ZfeI5XOtrLB4cBYYFffUaRZq4BLtGRMaVDpbA8b9ADuB471nES2bBLwJWz4ru8gEtMxne1hw6XEZ7auBNZ7TiMbywE3AMNUOKVFI51CsUE/YBRwhO8owvvAedjwad9BZHMa6RSKDecCRwM/BDQlgj8PAwercEqXRjrFYIP+xKOeAZ6TlJO3gSuw4SO+g8jWaaRTDPGcukcQTwy22nOarFtHvLLH/iqcdNBIp9hs0B34MfA1oNpzmqx5EPguNlzgO4i0nEonKTbYG7gJONt3lAyYA1yGDf/jO4i0nkonaTYYBPwKGOw7SgrNJT4Nfh82jHyHkW2j0vHFBicD3yW+zke2bhZx2YzGhlqDPuVUOr7Z4ADgUuArQAfPaUrNE8BIbDjRdxApHJVOqbBBF2AE8C1gd89pfFoJPADcjg1neM4iRaDSKTU2qCReY/0C4Higjd9AiagDJgD3ABO03lS2qXRKWTz6+TxwLvG0qVV+AxWUA/4L3Et8rGal5zySEJVOWtigM3AScFr+Y+A1z7ZZTjxr35PARGw4328c8UGlk0Y2qCK+xWIQcFT+sYfPSFsQAs8Sl8yTwKuaQEtUOllhg57E5bOhiPYFeib07g6YT3zR3obHTGCarqeRTal0sswG7YnPhPVp9NjwdRegXf7RttFHs8lW1hEvRhcS7x4ty3/8gE8K5nVsWFPE30QyRKUjG7NBG+ICcsBHuhhPCk2lIyKJ0tQWIpIolY6IJEqlIyKJUumISKJUOiKSKJWOiCRKpSMiiVLpiEiiVDoikiiVjogkSqUjIolS6YhIolQ6IpIolY6IJEqlIyKJUumISKJUOiKSKJWOiCRKpSMiiVLpiEiiVDoikiiVjogkSqUjIolS6YhIolQ6IpIolY6IJEqlIyKJ+n/OIUZYWYZBtwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(namesDF.loc[namesDF['wikiPage'] == 'NaN'])/len(namesDF)*100\n",
    "import matplotlib.pyplot as plt\n",
    "plt.pie([len(namesDF.loc[namesDF['wikiPage'] == 'NaN']),len(namesDF)],labels = ['Not Found','Found'], autopct='%1.1f%%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A. Walton Litz',\n",
       " 'A Dictionary of Canadianisms on Historical Principles',\n",
       " 'A Dictionary of the English Language',\n",
       " 'A New English Dictionary',\n",
       " 'All singing, all dancing (idiom)',\n",
       " 'American Civil War',\n",
       " 'American English',\n",
       " 'American and British English spelling differences',\n",
       " 'An Anglo-Saxon Dictionary',\n",
       " 'An Universal Etymological English Dictionary',\n",
       " 'Annotation',\n",
       " 'Antedating (lexicography)',\n",
       " 'Anthony Burgess',\n",
       " 'Anu Garg',\n",
       " 'Appendicitis',\n",
       " 'Application software',\n",
       " 'Arts Council of Great Britain',\n",
       " 'Australian English',\n",
       " 'Australian Oxford Dictionary',\n",
       " 'Balderdash and Piffle',\n",
       " 'Bausch & Lomb',\n",
       " 'Bible',\n",
       " 'Big Ideas (TV series)',\n",
       " 'Book sales club',\n",
       " 'British English',\n",
       " 'British Museum',\n",
       " 'Broadmoor Hospital',\n",
       " 'CD-ROM',\n",
       " \"Cambridge Advanced Learner's Dictionary\",\n",
       " 'Cambridge University Press',\n",
       " 'Canadian English',\n",
       " 'Canadian Oxford Dictionary',\n",
       " 'Canadian Press',\n",
       " 'Catholicon Anglicum',\n",
       " 'Century Dictionary',\n",
       " 'Chambers Dictionary',\n",
       " 'Charles Richardson (lexicographer)',\n",
       " 'Charles Talbut Onions',\n",
       " 'Charlotte Brewer',\n",
       " 'Collaborative International Dictionary of English',\n",
       " 'Collins COBUILD Advanced Dictionary',\n",
       " 'Collins English Dictionary',\n",
       " 'Compact Oxford English Dictionary of Current English',\n",
       " 'Concise Oxford English Dictionary',\n",
       " 'Coronation of Edward VII and Alexandra',\n",
       " 'Corpus linguistics',\n",
       " 'Corrugated iron',\n",
       " 'Countdown (game show)',\n",
       " 'Cursor Mundi',\n",
       " 'Descriptive grammar',\n",
       " 'Deutsches Wörterbuch',\n",
       " 'Dewey Decimal Classification',\n",
       " 'Diccionario de la lengua española',\n",
       " 'Dictionary of American English',\n",
       " 'Dictionary of American Regional English',\n",
       " 'Dictionary of Canadianisms on Historical Principles',\n",
       " 'Dictionary of Newfoundland English',\n",
       " 'Dictionary of Old English',\n",
       " \"Dictionnaire de l'Académie française\",\n",
       " 'Doi (identifier)',\n",
       " 'Early English Text Society',\n",
       " 'Edmund Spenser',\n",
       " 'Edmund Weiner',\n",
       " 'Edward VII',\n",
       " 'Emulator',\n",
       " \"Encarta Webster's Dictionary\",\n",
       " 'English-speaking world',\n",
       " 'English as a second or foreign language',\n",
       " 'English language',\n",
       " 'Etymology',\n",
       " 'Everest',\n",
       " 'Farmer Giles of Ham',\n",
       " 'Francis George Fowler',\n",
       " 'Francis March',\n",
       " 'Frank Tompa',\n",
       " 'Frederick James Furnivall',\n",
       " 'Fuck',\n",
       " 'Gage Canadian Dictionary',\n",
       " 'Gaston Gonnet',\n",
       " 'George Eliot',\n",
       " 'Grimm brothers',\n",
       " 'Hamlet',\n",
       " 'Harper Collins',\n",
       " 'HathiTrust',\n",
       " 'Headword',\n",
       " 'Henry Bradley',\n",
       " 'Henry Nicol',\n",
       " 'Henry Sweet',\n",
       " 'Henry Watson Fowler',\n",
       " 'Herbert Coleridge',\n",
       " 'Historical dictionary',\n",
       " 'IBM',\n",
       " 'ISBN (identifier)',\n",
       " 'ISSN (identifier)',\n",
       " 'International Phonetic Alphabet',\n",
       " 'Internet Archive',\n",
       " 'J. R. R. Tolkien',\n",
       " 'JSTOR (identifier)',\n",
       " 'James Gleick',\n",
       " 'James Murray (lexicographer)',\n",
       " 'John Milton',\n",
       " 'John Simpson (lexicographer)',\n",
       " 'John Willinsky',\n",
       " 'Jonathon Green',\n",
       " 'Joseph Emerson Worcester',\n",
       " 'Joseph Wright (linguist)',\n",
       " 'Kangxi Dictionary',\n",
       " 'King James Bible',\n",
       " 'LCCN (identifier)',\n",
       " 'LCC (identifier)',\n",
       " 'LEXX (text editor)',\n",
       " 'Lexicography',\n",
       " 'Liberal arts college',\n",
       " 'List of Countdown champions',\n",
       " 'List of Deans of Westminster',\n",
       " 'List of English dictionaries',\n",
       " 'List of contributors to the Oxford English Dictionary',\n",
       " 'List of online dictionaries',\n",
       " 'Loan word',\n",
       " 'Longman Dictionary of Contemporary English',\n",
       " 'Los Angeles Times',\n",
       " 'MP3',\n",
       " 'Macmillan English Dictionary for Advanced Learners',\n",
       " 'Macquarie Dictionary',\n",
       " 'Magnifying glass',\n",
       " 'Marie Curie',\n",
       " 'Markup (computer programming)',\n",
       " 'Markup language',\n",
       " 'Megabyte',\n",
       " 'Mel Gibson',\n",
       " \"Merriam-Webster's Advanced Learner's English Dictionary\",\n",
       " 'Michael Proffitt',\n",
       " 'Microsoft Windows',\n",
       " 'Middle English',\n",
       " 'Middle English Dictionary',\n",
       " 'Mike Cowlishaw',\n",
       " 'Mill Hill',\n",
       " \"Monolingual learner's dictionary\",\n",
       " 'N-up',\n",
       " 'New Oxford American Dictionary',\n",
       " 'New Oxford Dictionary of English',\n",
       " 'Nobel Prize in Physics',\n",
       " 'OCLC (identifier)',\n",
       " 'OED',\n",
       " 'OED (disambiguation)',\n",
       " 'OL (identifier)',\n",
       " 'OUP',\n",
       " 'Old English',\n",
       " 'Open Text Corporation',\n",
       " 'Oxford',\n",
       " 'Oxford, England',\n",
       " \"Oxford Advanced Learner's Dictionary\",\n",
       " 'Oxford Dictionary of English',\n",
       " 'Oxford University',\n",
       " 'Oxford University Press',\n",
       " 'Oxford dictionary (disambiguation)',\n",
       " 'Oxford spelling',\n",
       " 'PMC (identifier)',\n",
       " 'Penguin English Dictionary',\n",
       " 'Penny (British pre-decimal coin)',\n",
       " 'Peter Gilliver',\n",
       " 'Philip Lyttelton Gell',\n",
       " 'Philological Society',\n",
       " 'Pierre Curie',\n",
       " 'Prescriptive grammar',\n",
       " 'Princeton University',\n",
       " 'Princeton University Press',\n",
       " 'Pronunciation',\n",
       " 'Quotation',\n",
       " 'R v Penguin Books Ltd.',\n",
       " 'Radium',\n",
       " \"Random House Webster's Unabridged Dictionary\",\n",
       " 'Real Academia Española',\n",
       " 'Reed Tech',\n",
       " 'Retronym',\n",
       " 'Richard Boston',\n",
       " 'Richard Chenevix Trench',\n",
       " 'Robert Burchfield',\n",
       " 'Roy Harris (linguist)',\n",
       " 'S2CID (identifier)',\n",
       " 'SGML',\n",
       " 'SUDOC (identifier)',\n",
       " 'Samuel Beckett',\n",
       " 'Saturday Review (London)',\n",
       " 'Schizophrenia',\n",
       " 'Scriptorium',\n",
       " 'Sean Penn',\n",
       " 'Search engine (computing)',\n",
       " 'Serial (literature)',\n",
       " 'Shakespeare',\n",
       " 'Shilling',\n",
       " 'Shit',\n",
       " 'Shorter Oxford English Dictionary',\n",
       " 'Simon Winchester',\n",
       " 'Stanley Baldwin',\n",
       " 'Synonyms',\n",
       " 'TVOntario',\n",
       " 'Text editor',\n",
       " 'The American Heritage Dictionary of the English Language',\n",
       " 'The Australian National Dictionary',\n",
       " 'The English Schoole-Master',\n",
       " 'The Guardian',\n",
       " 'The Imperial Dictionary of the English Language',\n",
       " 'The Irish Times',\n",
       " 'The Meaning of Everything: The Story of the Oxford English Dictionary',\n",
       " 'The New World of English Words',\n",
       " 'The Professor and the Madman: A Tale of Murder, Insanity, and the Making of the Oxford English Dictionary',\n",
       " 'The Professor and the Madman (film)',\n",
       " 'The Surgeon of Crowthorne',\n",
       " 'Tim Bray',\n",
       " 'Time (magazine)',\n",
       " 'Toronto Star',\n",
       " 'Transliteration',\n",
       " 'Tuberculosis',\n",
       " 'Typesetting',\n",
       " 'Typography',\n",
       " 'University of Waterloo',\n",
       " 'Urban Dictionary',\n",
       " 'Usenet (identifier)',\n",
       " 'Usenet newsgroup',\n",
       " 'VIAF (identifier)',\n",
       " 'Victorian morals',\n",
       " 'Virginia Woolf',\n",
       " 'Vocabolario degli Accademici della Crusca',\n",
       " \"Webster's Dictionary\",\n",
       " \"Webster's New World Dictionary\",\n",
       " \"Webster's Third New International Dictionary\",\n",
       " 'Wiktionary',\n",
       " 'William Chester Minor',\n",
       " 'William Craigie',\n",
       " 'William Shakespeare',\n",
       " 'Wonders of the world',\n",
       " 'Woordenboek der Nederlandsche Taal',\n",
       " 'Wordhunt',\n",
       " 'Wordnik',\n",
       " 'World Book Dictionary',\n",
       " 'World Wide Web',\n",
       " 'XML',\n",
       " 'Yale University Press',\n",
       " 'YouTube']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rick Riordan']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = '9781417732470'\n",
    "url = isbnAPI + title\n",
    "response = urlopen(url)\n",
    "data = json.loads(response.read())\n",
    "data['items'][0]['volumeInfo']['authors']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What might be worthwhile until I can get the library books, is a random book selector. That way I can see how efficient the code is\n",
    "https://www.generatormix.com/random-book-generator\n",
    "https://www.bestrandoms.com/random-book-generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "- if the isbn lookup doesnt work, then try the title lookup\n",
    "    - The google books isbn api is small, try to get access to another\n",
    "- Some authors don't have a wikipedia page, so we need to search for them\n",
    "- Maybe if they lack a wiki article, THEN do the name search? I dunnoooooo\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03b31e0dbf5ee774e49906e1a4e99cf39d3bc46df0e15af7b9d16b1e9b24f047"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
